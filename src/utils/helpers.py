"""ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤"""

import re
import hashlib
from datetime import datetime, timezone
from typing import Optional, Union, List
from urllib.parse import urlparse, urljoin
from src.models.exceptions import InvalidUrlException

def parse_timestamp(timestamp: Union[int, str, datetime]) -> datetime:
    """ë‹¤ì–‘í•œ í˜•ì‹ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜
    
    Args:
        timestamp: UNIX íƒ€ì„ìŠ¤íƒ¬í”„(ì´ˆ/ë°€ë¦¬ì´ˆ), ISO ë¬¸ìì—´, ë˜ëŠ” datetime ê°ì²´
        
    Returns:
        datetime: UTC ê¸°ì¤€ datetime ê°ì²´
        
    Raises:
        ValueError: ë³€í™˜í•  ìˆ˜ ì—†ëŠ” í˜•ì‹ì¸ ê²½ìš°
    """
    if isinstance(timestamp, datetime):
        return timestamp.replace(tzinfo=timezone.utc) if timestamp.tzinfo is None else timestamp
    
    if isinstance(timestamp, str):
        # ISO í˜•ì‹ ë¬¸ìì—´ íŒŒì‹±
        try:
            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            return dt.replace(tzinfo=timezone.utc) if dt.tzinfo is None else dt
        except ValueError:
            # ìˆ«ì ë¬¸ìì—´ì¼ ìˆ˜ ìˆìŒ
            try:
                timestamp = int(timestamp)
            except ValueError:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤: {timestamp}")
    
    if isinstance(timestamp, int):
        # UNIX íƒ€ì„ìŠ¤íƒ¬í”„ ì²˜ë¦¬
        # ë°€ë¦¬ì´ˆ ë‹¨ìœ„ì¸ì§€ í™•ì¸ (13ìë¦¬ ì´ìƒ)
        if timestamp > 10**10:
            timestamp_float = timestamp / 1000
        else:
            timestamp_float = float(timestamp)
        
        return datetime.fromtimestamp(timestamp_float, tz=timezone.utc)
    
    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ì…ë‹ˆë‹¤: {type(timestamp)}")

def validate_url(url: str) -> bool:
    """URL ìœ íš¨ì„± ê²€ì¦
    
    Args:
        url: ê²€ì¦í•  URL
        
    Returns:
        bool: ìœ íš¨í•œ URLì¸ì§€ ì—¬ë¶€
    """
    try:
        parsed = urlparse(url)
        return all([parsed.scheme, parsed.netloc])
    except Exception:
        return False

def normalize_url(url: str, base_url: Optional[str] = None) -> str:
    """URL ì •ê·œí™”
    
    Args:
        url: ì •ê·œí™”í•  URL
        base_url: ìƒëŒ€ URLì¸ ê²½ìš° ê¸°ì¤€ì´ ë  ë² ì´ìŠ¤ URL
        
    Returns:
        str: ì •ê·œí™”ëœ ì ˆëŒ€ URL
        
    Raises:
        InvalidUrlException: ìœ íš¨í•˜ì§€ ì•Šì€ URLì¸ ê²½ìš°
    """
    if not url:
        raise InvalidUrlException(url)
    
    # ìƒëŒ€ URLì¸ ê²½ìš° ì ˆëŒ€ URLë¡œ ë³€í™˜
    if base_url and not url.startswith(('http://', 'https://')):
        url = urljoin(base_url, url)
    
    if not validate_url(url):
        raise InvalidUrlException(url)
    
    return url

def extract_article_id(url: str) -> Optional[str]:
    """URLì—ì„œ ê²Œì‹œê¸€ ID ì¶”ì¶œ
    
    Args:
        url: ê²Œì‹œê¸€ URL
        
    Returns:
        Optional[str]: ì¶”ì¶œëœ ê²Œì‹œê¸€ ID, ì—†ìœ¼ë©´ None
    """
    # ë‹¤ì–‘í•œ íŒ¨í„´ì˜ ê²Œì‹œê¸€ ID ì¶”ì¶œ
    patterns = [
        r'/view/(\d+)',
        r'/article/(\d+)',
        r'article_id=(\d+)',
        r'id=(\d+)',
        r'/(\d+)$',
        r'/(\d+)/',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    
    return None

def clean_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ ì •ì œ
    
    Args:
        text: ì •ì œí•  í…ìŠ¤íŠ¸
        
    Returns:
        str: ì •ì œëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return ""
    
    # HTML íƒœê·¸ ì œê±°
    text = re.sub(r'<[^>]+>', '', text)
    
    # ì—°ì†ëœ ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text)
    
    # ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()
    
    return text

def generate_news_id(title: str, url: str, published_at: datetime) -> str:
    """ë‰´ìŠ¤ ê³ ìœ  ID ìƒì„±
    
    Args:
        title: ë‰´ìŠ¤ ì œëª©
        url: ë‰´ìŠ¤ URL
        published_at: ë°œí–‰ ì¼ì‹œ
        
    Returns:
        str: ê³ ìœ  ID (í•´ì‹œê°’)
    """
    # URLì—ì„œ ê²Œì‹œê¸€ ID ì¶”ì¶œ ì‹œë„
    article_id = extract_article_id(url)
    if article_id:
        return article_id
    
    # ì œëª©, URL, ë°œí–‰ì¼ì‹œë¥¼ ì¡°í•©í•˜ì—¬ í•´ì‹œ ìƒì„±
    content = f"{title}|{url}|{published_at.isoformat()}"
    return hashlib.md5(content.encode('utf-8')).hexdigest()[:12]

def is_important_news(title: str, keywords: Optional[List[str]] = None) -> bool:
    """ì¤‘ìš” ë‰´ìŠ¤ ì—¬ë¶€ íŒë‹¨
    
    Args:
        title: ë‰´ìŠ¤ ì œëª©
        keywords: ì¤‘ìš” í‚¤ì›Œë“œ ëª©ë¡ (ê¸°ë³¸ê°’: ë‚´ì¥ í‚¤ì›Œë“œ)
        
    Returns:
        bool: ì¤‘ìš” ë‰´ìŠ¤ ì—¬ë¶€
    """
    if not keywords:
        keywords = [
            'ê¸´ê¸‰', 'ì¤‘ìš”', 'í•„ë…', 'ê³µì§€', 'ì ê²€', 'ì—…ë°ì´íŠ¸', 'íŒ¨ì¹˜',
            'ì´ë²¤íŠ¸', 'ë³´ìƒ', 'ë²„ê·¸', 'ìˆ˜ì •', 'ì‹ ê·œ', 'ì¶”ê°€', 'ë³€ê²½'
        ]
    
    title_lower = title.lower()
    
    # í‚¤ì›Œë“œ ë§¤ì¹­
    for keyword in keywords:
        if keyword.lower() in title_lower:
            return True
    
    # íŠ¹ìˆ˜ ë¬¸ì íŒ¨í„´ (ğŸ“Œ, âš ï¸, ğŸ”¥ ë“±)
    if re.search(r'[ğŸ“Œâš ï¸ğŸ”¥â—ï¸â€¼ï¸]', title):
        return True
    
    return False

def extract_tags_from_title(title: str) -> List[str]:
    """ì œëª©ì—ì„œ íƒœê·¸ ì¶”ì¶œ
    
    Args:
        title: ë‰´ìŠ¤ ì œëª©
        
    Returns:
        List[str]: ì¶”ì¶œëœ íƒœê·¸ ëª©ë¡
    """
    tags = []
    
    # ëŒ€ê´„í˜¸ ì•ˆì˜ íƒœê·¸ ì¶”ì¶œ [íƒœê·¸]
    bracket_tags = re.findall(r'\[([^\]]+)\]', title)
    tags.extend(bracket_tags)
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ íƒœê·¸ ì¶”ì¶œ
    keyword_tags = {
        'ì ê²€': ['ì ê²€', 'maintenance'],
        'ì—…ë°ì´íŠ¸': ['ì—…ë°ì´íŠ¸', 'update', 'íŒ¨ì¹˜', 'patch'],
        'ì´ë²¤íŠ¸': ['ì´ë²¤íŠ¸', 'event'],
        'ê³µì§€': ['ê³µì§€', 'notice', 'announcement'],
        'ë²„ê·¸': ['ë²„ê·¸', 'bug', 'ìˆ˜ì •', 'fix'],
        'ì‹ ê·œ': ['ì‹ ê·œ', 'new', 'ì¶”ê°€', 'add'],
    }
    
    title_lower = title.lower()
    for tag, keywords in keyword_tags.items():
        if any(keyword in title_lower for keyword in keywords):
            tags.append(tag)
    
    return list(set(tags))  # ì¤‘ë³µ ì œê±°

def format_view_count(count: Optional[int]) -> str:
    """ì¡°íšŒìˆ˜ í¬ë§·íŒ…
    
    Args:
        count: ì¡°íšŒìˆ˜
        
    Returns:
        str: í¬ë§·ëœ ì¡°íšŒìˆ˜ ë¬¸ìì—´
    """
    if count is None:
        return "0"
    
    if count >= 1000000:
        return f"{count/1000000:.1f}M"
    elif count >= 1000:
        return f"{count/1000:.1f}K"
    else:
        return str(count)

def truncate_text(text: str, max_length: int = 100, suffix: str = "...") -> str:
    """í…ìŠ¤íŠ¸ ìë¥´ê¸°
    
    Args:
        text: ìë¥¼ í…ìŠ¤íŠ¸
        max_length: ìµœëŒ€ ê¸¸ì´
        suffix: ìë¥¸ ê²½ìš° ì¶”ê°€í•  ì ‘ë¯¸ì‚¬
        
    Returns:
        str: ìë¥¸ í…ìŠ¤íŠ¸
    """
    if not text or len(text) <= max_length:
        return text
    
    return text[:max_length - len(suffix)] + suffix 