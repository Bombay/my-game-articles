"""ì—í”½ì„¸ë¸ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸"""

import pytest
import asyncio
from datetime import datetime
from unittest.mock import AsyncMock, patch

from src.scrapers.epic_seven import EpicSevenScraper
from src.models.game_news import GameNews, NewsType, GameType
from src.models.exceptions import ScrapingException


class TestEpicSevenScraper:
    """ì—í”½ì„¸ë¸ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def scraper(self):
        """ìŠ¤í¬ë˜í¼ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        return EpicSevenScraper()
    
    @pytest.fixture
    def mock_api_response(self):
        """ëª¨í‚¹ëœ API ì‘ë‹µ"""
        return {
            "value": {
                "list": [
                    {
                        "article_id": 12345,
                        "title": "[ê³µì§€] ì—í”½ì„¸ë¸ ì •ê¸° ì ê²€ ì•ˆë‚´",
                        "create_datetime": 1704844800000,  # 2024-01-10 00:00:00
                        "content": "ì •ê¸° ì ê²€ì´ ì‹¤ì‹œë©ë‹ˆë‹¤.",
                        "summary": "ì •ê¸° ì ê²€ ì•ˆë‚´ì…ë‹ˆë‹¤.",
                        "view_count": 15000,
                        "is_headline": True,
                        "category": "ê³µì§€",
                        "article_type": "official"
                    },
                    {
                        "article_id": 12346,
                        "title": "ğŸ‰ ì‹ ê·œ ì˜ì›… ì¶œì‹œ ì´ë²¤íŠ¸",
                        "create_datetime": 1704758400000,  # 2024-01-09 00:00:00
                        "content": "ì‹ ê·œ ì˜ì›… ì¶œì‹œ ì´ë²¤íŠ¸ê°€ ì‹œì‘ë©ë‹ˆë‹¤.",
                        "summary": "ì‹ ê·œ ì˜ì›… ì´ë²¤íŠ¸",
                        "view_count": 8000,
                        "is_headline": False,
                        "category": "ì´ë²¤íŠ¸",
                        "article_type": "event"
                    }
                ]
            }
        }
    
    @pytest.fixture
    def mock_detail_response(self):
        """ëª¨í‚¹ëœ ìƒì„¸ API ì‘ë‹µ"""
        return {
            "value": {
                "article_id": 12345,
                "title": "[ê³µì§€] ì—í”½ì„¸ë¸ ì •ê¸° ì ê²€ ì•ˆë‚´",
                "create_datetime": 1704844800000,
                "content": "ì •ê¸° ì ê²€ì´ ì‹¤ì‹œë©ë‹ˆë‹¤. ìƒì„¸í•œ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤...",
                "summary": "ì •ê¸° ì ê²€ ì•ˆë‚´ì…ë‹ˆë‹¤.",
                "view_count": 15000,
                "is_headline": True,
                "category": "ê³µì§€",
                "article_type": "official"
            }
        }
    
    @pytest.mark.asyncio
    async def test_get_announcements(self, scraper, mock_api_response):
        """ê³µì§€ì‚¬í•­ ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
        with patch.object(scraper, 'make_request') as mock_request:
            mock_response = AsyncMock()
            mock_response.json.return_value = mock_api_response
            mock_request.return_value = mock_response
            
            announcements = await scraper.get_announcements()
            
            assert len(announcements) == 2
            assert all(isinstance(news, GameNews) for news in announcements)
            assert announcements[0].game == GameType.EPIC_SEVEN
            assert announcements[0].category == NewsType.ANNOUNCEMENT
            assert "ğŸ“Œ" in announcements[0].title  # ì¤‘ìš”ë„ ì´ëª¨ì§€
            assert "ğŸ”¥" in announcements[0].title  # ì¡°íšŒìˆ˜ ì´ëª¨ì§€
            assert "ğŸ“¢" in announcements[0].title  # ê³µì§€ì‚¬í•­ ì´ëª¨ì§€
    
    @pytest.mark.asyncio
    async def test_get_events(self, scraper, mock_api_response):
        """ì´ë²¤íŠ¸ ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
        with patch.object(scraper, 'make_request') as mock_request:
            mock_response = AsyncMock()
            mock_response.json.return_value = mock_api_response
            mock_request.return_value = mock_response
            
            events = await scraper.get_events()
            
            assert len(events) == 2
            assert all(news.category == NewsType.EVENT for news in events)
            assert "ğŸ‰" in events[0].title  # ì´ë²¤íŠ¸ ì´ëª¨ì§€
    
    @pytest.mark.asyncio
    async def test_get_updates(self, scraper, mock_api_response):
        """ì—…ë°ì´íŠ¸ ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
        with patch.object(scraper, 'make_request') as mock_request:
            mock_response = AsyncMock()
            mock_response.json.return_value = mock_api_response
            mock_request.return_value = mock_response
            
            updates = await scraper.get_updates()
            
            assert len(updates) == 2
            assert all(news.category == NewsType.UPDATE for news in updates)
            assert "ğŸ”„" in updates[0].title  # ì—…ë°ì´íŠ¸ ì´ëª¨ì§€
    
    @pytest.mark.asyncio
    async def test_get_announcement_detail(self, scraper, mock_detail_response):
        """ê³µì§€ì‚¬í•­ ìƒì„¸ ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
        test_url = "https://page.onstove.com/epicseven/global/view/12345"
        
        with patch.object(scraper, 'make_request') as mock_request:
            mock_response = AsyncMock()
            mock_response.json.return_value = mock_detail_response
            mock_request.return_value = mock_response
            
            detail = await scraper.get_announcement_detail(test_url)
            
            assert detail is not None
            assert detail.id == "12345"
            assert detail.category == NewsType.ANNOUNCEMENT
            assert detail.content is not None
            assert len(detail.content) > len(detail.summary)
    
    @pytest.mark.asyncio
    async def test_get_detail_fallback(self, scraper, mock_api_response):
        """ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ ì‹œ fallback í…ŒìŠ¤íŠ¸"""
        test_url = "https://page.onstove.com/epicseven/global/view/12345"
        
        with patch.object(scraper, 'make_request') as mock_request:
            # ì²« ë²ˆì§¸ í˜¸ì¶œ(ìƒì„¸ API)ì€ ì‹¤íŒ¨, ë‘ ë²ˆì§¸ í˜¸ì¶œ(ëª©ë¡ API)ì€ ì„±ê³µ
            mock_response = AsyncMock()
            mock_response.json.return_value = mock_api_response
            mock_request.side_effect = [Exception("API ì˜¤ë¥˜"), mock_response]
            
            detail = await scraper.get_announcement_detail(test_url)
            
            assert detail is not None
            assert detail.id == "12345"
            assert detail.content == detail.summary  # fallbackì—ì„œëŠ” summaryë¥¼ contentë¡œ ì‚¬ìš©
    
    def test_extract_article_id_from_url(self, scraper):
        """URLì—ì„œ article_id ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        test_urls = [
            "https://page.onstove.com/epicseven/global/view/12345",
            "https://page.onstove.com/epicseven/global/view/67890",
            "https://invalid-url.com"
        ]
        
        assert scraper._extract_article_id_from_url(test_urls[0]) == "12345"
        assert scraper._extract_article_id_from_url(test_urls[1]) == "67890"
        assert scraper._extract_article_id_from_url(test_urls[2]) is None
    
    def test_is_important_article(self, scraper):
        """ì¤‘ìš”ë„ íŒë‹¨ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            # ì¤‘ìš”í•œ ê²Œì‹œê¸€
            {"title": "ê¸´ê¸‰ ì ê²€ ì•ˆë‚´", "is_headline": False, "view_count": 5000},
            {"title": "ì¼ë°˜ ê³µì§€", "is_headline": True, "view_count": 1000},
            {"title": "ì¸ê¸° ì´ë²¤íŠ¸", "is_headline": False, "view_count": 15000},
            # ì¤‘ìš”í•˜ì§€ ì•Šì€ ê²Œì‹œê¸€
            {"title": "ì¼ë°˜ ê²Œì‹œê¸€", "is_headline": False, "view_count": 100},
        ]
        
        assert scraper._is_important_article(test_cases[0]) is True  # ê¸´ê¸‰ í‚¤ì›Œë“œ
        assert scraper._is_important_article(test_cases[1]) is True  # ê³ ì • ê²Œì‹œë¬¼
        assert scraper._is_important_article(test_cases[2]) is True  # ë†’ì€ ì¡°íšŒìˆ˜
        assert scraper._is_important_article(test_cases[3]) is False  # ì¼ë°˜ ê²Œì‹œê¸€
    
    def test_extract_tags(self, scraper):
        """íƒœê·¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        test_article = {
            "title": "[ê³µì§€] ì •ê¸° ì ê²€ ì•ˆë‚´ - ì—…ë°ì´íŠ¸ í¬í•¨",
            "category": "ê³µì§€ì‚¬í•­",
            "article_type": "official"
        }
        
        tags = scraper._extract_tags(test_article)
        
        assert "ê³µì§€" in tags
        assert "ì ê²€" in tags
        assert "ì—…ë°ì´íŠ¸" in tags
        assert "ê³µì§€ì‚¬í•­" in tags
        assert "official" in tags
    
    def test_decorate_title(self, scraper):
        """ì œëª© ì¥ì‹ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            # ì¤‘ìš”í•œ ê³µì§€ì‚¬í•­ (ë†’ì€ ì¡°íšŒìˆ˜)
            {
                "title": "ì •ê¸° ì ê²€ ì•ˆë‚´",
                "category": NewsType.ANNOUNCEMENT,
                "is_important": True,
                "view_count": 15000
            },
            # ì¼ë°˜ ì´ë²¤íŠ¸
            {
                "title": "ì‹ ê·œ ì˜ì›… ì¶œì‹œ",
                "category": NewsType.EVENT,
                "is_important": False,
                "view_count": 5000
            },
            # ì—…ë°ì´íŠ¸
            {
                "title": "ë²„ì „ ì—…ë°ì´íŠ¸",
                "category": NewsType.UPDATE,
                "is_important": False,
                "view_count": 3000
            }
        ]
        
        decorated1 = scraper._decorate_title(**test_cases[0])
        assert "ğŸ“Œ" in decorated1  # ì¤‘ìš”ë„
        assert "ğŸ”¥" in decorated1  # ë†’ì€ ì¡°íšŒìˆ˜
        assert "ğŸ“¢" in decorated1  # ê³µì§€ì‚¬í•­
        
        decorated2 = scraper._decorate_title(**test_cases[1])
        assert "ğŸ“Œ" not in decorated2  # ì¤‘ìš”í•˜ì§€ ì•ŠìŒ
        assert "ğŸ”¥" not in decorated2  # ì¡°íšŒìˆ˜ ë‚®ìŒ
        assert "ğŸ‰" in decorated2  # ì´ë²¤íŠ¸
        
        decorated3 = scraper._decorate_title(**test_cases[2])
        assert "ğŸ”„" in decorated3  # ì—…ë°ì´íŠ¸
    
    @pytest.mark.asyncio
    async def test_error_handling(self, scraper):
        """ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        with patch.object(scraper, 'make_request') as mock_request:
            mock_request.side_effect = Exception("ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜")
            
            with pytest.raises(ScrapingException):
                await scraper.get_announcements()
    
    @pytest.mark.asyncio
    async def test_invalid_response_format(self, scraper):
        """ì˜ëª»ëœ ì‘ë‹µ í˜•ì‹ í…ŒìŠ¤íŠ¸"""
        invalid_response = {"error": "Invalid request"}
        
        with patch.object(scraper, 'make_request') as mock_request:
            mock_response = AsyncMock()
            mock_response.json.return_value = invalid_response
            mock_request.return_value = mock_response
            
            with pytest.raises(ScrapingException):
                await scraper.get_announcements()


if __name__ == "__main__":
    # ê°„ë‹¨í•œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
    async def test_run():
        scraper = EpicSevenScraper()
        try:
            async with scraper:
                print("ì—í”½ì„¸ë¸ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
                
                # ê³µì§€ì‚¬í•­ í…ŒìŠ¤íŠ¸
                announcements = await scraper.get_announcements()
                print(f"ê³µì§€ì‚¬í•­ {len(announcements)}ê°œ ì¡°íšŒ ì„±ê³µ")
                
                # ì´ë²¤íŠ¸ í…ŒìŠ¤íŠ¸
                events = await scraper.get_events()
                print(f"ì´ë²¤íŠ¸ {len(events)}ê°œ ì¡°íšŒ ì„±ê³µ")
                
                # ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸
                updates = await scraper.get_updates()
                print(f"ì—…ë°ì´íŠ¸ {len(updates)}ê°œ ì¡°íšŒ ì„±ê³µ")
                
                # ìƒì„¸ ì •ë³´ í…ŒìŠ¤íŠ¸
                if announcements:
                    first_url = announcements[0].url
                    print(f"ì²« ë²ˆì§¸ ê³µì§€ì‚¬í•­ URL: {first_url}")
                    print(f"URL íƒ€ì…: {type(first_url)}")
                    article_id = scraper._extract_article_id_from_url(str(first_url))
                    print(f"ì¶”ì¶œëœ article_id: {article_id}")
                    
                    try:
                        detail = await scraper.get_announcement_detail(str(first_url))
                        print(f"ìƒì„¸ ì •ë³´ ì¡°íšŒ {'ì„±ê³µ' if detail else 'ì‹¤íŒ¨'}")
                    except Exception as e:
                        print(f"ìƒì„¸ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
                        print(f"ì˜¤ë¥˜ íƒ€ì…: {type(e)}")
                
                print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
                
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(test_run()) 