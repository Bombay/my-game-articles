"""ì‹¤ì œ API í˜¸ì¶œ í†µí•© í…ŒìŠ¤íŠ¸"""

import asyncio
import time
import pytest
from src.scrapers.lordnine import LordnineScraper
from src.scrapers.epic_seven import EpicSevenScraper
from src.scrapers.lost_ark import LostArkScraper
from src.models.game_news import NewsType


class TestRealAPIIntegration:
    """ì‹¤ì œ API í˜¸ì¶œ í†µí•© í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_lordnine_announcements(self):
        """ë¡œë“œë‚˜ì¸ ê³µì§€ì‚¬í•­ ì‹¤ì œ API í…ŒìŠ¤íŠ¸"""
        async with LordnineScraper() as scraper:
            start_time = time.time()
            
            try:
                announcements = await scraper.get_announcements()
                execution_time = time.time() - start_time
                
                print(f"ë¡œë“œë‚˜ì¸ ê³µì§€ì‚¬í•­: {len(announcements)}ê°œ ì¡°íšŒë¨ ({execution_time:.2f}ì´ˆ)")
                
                if announcements:
                    first_news = announcements[0]
                    print(f"ì²« ë²ˆì§¸ ë‰´ìŠ¤: {first_news.title}")
                    print(f"URL: {first_news.url}")
                    print(f"ì¹´í…Œê³ ë¦¬: {first_news.category}")
                    
                    # ê¸°ë³¸ ê²€ì¦
                    assert first_news.game == "lordnine"
                    assert first_news.category == NewsType.ANNOUNCEMENT
                    assert first_news.title
                    assert first_news.url
                    assert first_news.published_at
                
                # ì„±ëŠ¥ ê²€ì¦ (10ì´ˆ ì´ë‚´)
                assert execution_time < 10.0
                
                print("âœ… ë¡œë“œë‚˜ì¸ ê³µì§€ì‚¬í•­ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                
            except Exception as e:
                print(f"âŒ ë¡œë“œë‚˜ì¸ ê³µì§€ì‚¬í•­ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                # ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ë“±ì€ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
                return
    
    @pytest.mark.asyncio
    async def test_epic_seven_announcements(self):
        """ì—í”½ì„¸ë¸ ê³µì§€ì‚¬í•­ ì‹¤ì œ API í…ŒìŠ¤íŠ¸"""
        async with EpicSevenScraper() as scraper:
            start_time = time.time()
            
            try:
                announcements = await scraper.get_announcements()
                execution_time = time.time() - start_time
                
                print(f"ì—í”½ì„¸ë¸ ê³µì§€ì‚¬í•­: {len(announcements)}ê°œ ì¡°íšŒë¨ ({execution_time:.2f}ì´ˆ)")
                
                if announcements:
                    first_news = announcements[0]
                    print(f"ì²« ë²ˆì§¸ ë‰´ìŠ¤: {first_news.title}")
                    print(f"URL: {first_news.url}")
                    print(f"ì¹´í…Œê³ ë¦¬: {first_news.category}")
                    
                    # ê¸°ë³¸ ê²€ì¦
                    assert first_news.game == "epic_seven"
                    assert first_news.category == NewsType.ANNOUNCEMENT
                    assert first_news.title
                    assert first_news.url
                    assert first_news.published_at
                
                # ì„±ëŠ¥ ê²€ì¦ (10ì´ˆ ì´ë‚´)
                assert execution_time < 10.0
                
                print("âœ… ì—í”½ì„¸ë¸ ê³µì§€ì‚¬í•­ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                
            except Exception as e:
                print(f"âŒ ì—í”½ì„¸ë¸ ê³µì§€ì‚¬í•­ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                return
    
    @pytest.mark.asyncio
    async def test_lost_ark_announcements(self):
        """ë¡œìŠ¤íŠ¸ì•„í¬ ê³µì§€ì‚¬í•­ ì‹¤ì œ API í…ŒìŠ¤íŠ¸"""
        async with LostArkScraper() as scraper:
            start_time = time.time()
            
            try:
                announcements = await scraper.get_announcements()
                execution_time = time.time() - start_time
                
                print(f"ë¡œìŠ¤íŠ¸ì•„í¬ ê³µì§€ì‚¬í•­: {len(announcements)}ê°œ ì¡°íšŒë¨ ({execution_time:.2f}ì´ˆ)")
                
                if announcements:
                    first_news = announcements[0]
                    print(f"ì²« ë²ˆì§¸ ë‰´ìŠ¤: {first_news.title}")
                    print(f"URL: {first_news.url}")
                    print(f"ì¹´í…Œê³ ë¦¬: {first_news.category}")
                    
                    # ê¸°ë³¸ ê²€ì¦
                    assert first_news.game == "lost_ark"
                    assert first_news.category == NewsType.ANNOUNCEMENT
                    assert first_news.title
                    assert first_news.url
                    assert first_news.published_at
                
                # ì„±ëŠ¥ ê²€ì¦ (10ì´ˆ ì´ë‚´, ë¡œìŠ¤íŠ¸ì•„í¬ëŠ” ë¸Œë¼ìš°ì € ìë™í™”ë¡œ ë” ëŠë¦´ ìˆ˜ ìˆìŒ)
                assert execution_time < 15.0
                
                print("âœ… ë¡œìŠ¤íŠ¸ì•„í¬ ê³µì§€ì‚¬í•­ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                
            except Exception as e:
                print(f"âŒ ë¡œìŠ¤íŠ¸ì•„í¬ ê³µì§€ì‚¬í•­ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                return
    
    @pytest.mark.asyncio
    async def test_concurrent_requests(self):
        """ë™ì‹œ ìš”ì²­ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        start_time = time.time()
        
        async def get_lordnine():
            async with LordnineScraper() as scraper:
                return await scraper.get_announcements()
        
        async def get_epic_seven():
            async with EpicSevenScraper() as scraper:
                return await scraper.get_announcements()
        
        try:
            # ë¡œë“œë‚˜ì¸ê³¼ ì—í”½ì„¸ë¸ ë™ì‹œ ì‹¤í–‰ (ë¡œìŠ¤íŠ¸ì•„í¬ëŠ” ë¸Œë¼ìš°ì € ë•Œë¬¸ì— ì œì™¸)
            results = await asyncio.gather(
                get_lordnine(),
                get_epic_seven(),
                return_exceptions=True
            )
            
            execution_time = time.time() - start_time
            print(f"ë™ì‹œ ìš”ì²­ ì™„ë£Œ ì‹œê°„: {execution_time:.2f}ì´ˆ")
            
            success_count = 0
            for i, result in enumerate(results):
                game_names = ["ë¡œë“œë‚˜ì¸", "ì—í”½ì„¸ë¸"]
                if isinstance(result, Exception):
                    print(f"{game_names[i]} ì‹¤íŒ¨: {result}")
                else:
                    print(f"{game_names[i]} ì„±ê³µ: {len(result)}ê°œ")
                    success_count += 1
            
            # ìµœì†Œ 1ê°œëŠ” ì„±ê³µí•´ì•¼ í•¨
            assert success_count >= 1
            
            # ë™ì‹œ ì‹¤í–‰ ì‹œê°„ì´ ê°œë³„ ì‹¤í–‰ë³´ë‹¤ ë¹¨ë¼ì•¼ í•¨ (15ì´ˆ ì´ë‚´)
            assert execution_time < 15.0
            
            print("âœ… ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            
        except Exception as e:
            print(f"âŒ ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return
    
    @pytest.mark.asyncio
    async def test_detail_retrieval(self):
        """ìƒì„¸ ì •ë³´ ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
        async with LordnineScraper() as scraper:
            try:
                # ê³µì§€ì‚¬í•­ ëª©ë¡ ì¡°íšŒ
                announcements = await scraper.get_announcements()
                
                if announcements:
                    first_url = str(announcements[0].url)
                    print(f"ìƒì„¸ ì¡°íšŒ URL: {first_url}")
                    
                    start_time = time.time()
                    detail = await scraper.get_announcement_detail(first_url)
                    execution_time = time.time() - start_time
                    
                    print(f"ìƒì„¸ ì¡°íšŒ ì‹œê°„: {execution_time:.2f}ì´ˆ")
                    
                    if detail:
                        print(f"ìƒì„¸ ì œëª©: {detail.title}")
                        print(f"ìƒì„¸ ë‚´ìš© ê¸¸ì´: {len(detail.content) if detail.content else 0}")
                        
                        # ìƒì„¸ ì •ë³´ ê²€ì¦
                        assert detail.title
                        assert detail.url
                        
                        # ì„±ëŠ¥ ê²€ì¦ (15ì´ˆ ì´ë‚´)
                        assert execution_time < 15.0
                        
                        print("âœ… ìƒì„¸ ì¡°íšŒ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                    else:
                        print("âš ï¸ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ (API ì œí•œì¼ ìˆ˜ ìˆìŒ)")
                else:
                    print("âš ï¸ ê³µì§€ì‚¬í•­ ëª©ë¡ì´ ì—†ì–´ì„œ ìƒì„¸ ì¡°íšŒ ë¶ˆê°€")
                    
            except Exception as e:
                print(f"âŒ ìƒì„¸ ì¡°íšŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                return


# ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡
if __name__ == "__main__":
    async def run_tests():
        test_instance = TestRealAPIIntegration()
        
        print("ğŸš€ ì‹¤ì œ API í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘...\n")
        
        await test_instance.test_lordnine_announcements()
        print()
        
        await test_instance.test_epic_seven_announcements()
        print()
        
        await test_instance.test_concurrent_requests()
        print()
        
        await test_instance.test_detail_retrieval()
        print()
        
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    asyncio.run(run_tests()) 