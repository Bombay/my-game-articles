# Task 08: ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° ì‹¤í–‰
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ êµ¬í˜„
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ìµœì í™”
- [ ] ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
- [ ] ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦

## ğŸ“ ìƒì„¸ ë‚´ìš©
### êµ¬í˜„í•  ê¸°ëŠ¥ë“¤
- ê° ìŠ¤í¬ë˜í¼ë³„ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- MCP ì„œë²„ í†µí•© í…ŒìŠ¤íŠ¸
- ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë° ì˜ˆì™¸ ìƒí™© í…ŒìŠ¤íŠ¸
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ë° ìµœì í™”

### í…ŒìŠ¤íŠ¸ ë²”ìœ„
```python
# í…ŒìŠ¤íŠ¸ ì¹´í…Œê³ ë¦¬
TEST_CATEGORIES = {
    "unit_tests": [
        "test_game_news_model",
        "test_lordnine_scraper", 
        "test_epic_seven_scraper",
        "test_lost_ark_scraper",
        "test_utils_helpers"
    ],
    "integration_tests": [
        "test_mcp_server_integration",
        "test_all_tools_registration",
        "test_cross_game_consistency"
    ],
    "performance_tests": [
        "test_response_time_limits",
        "test_concurrent_requests",
        "test_memory_usage"
    ],
    "error_handling_tests": [
        "test_network_failures",
        "test_invalid_urls",
        "test_api_changes"
    ]
}
```

## ğŸ› ï¸ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­
### ì‚¬ìš©í•  ê¸°ìˆ  ìŠ¤íƒ
- **pytest**: í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬
- **pytest-asyncio**: ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸
- **pytest-mock**: ëª¨í‚¹
- **pytest-benchmark**: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

### íŒŒì¼ êµ¬ì¡°
```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py               # í…ŒìŠ¤íŠ¸ ì„¤ì •
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_models.py        # ë°ì´í„° ëª¨ë¸ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_lordnine.py      # ë¡œë“œë‚˜ì¸ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_epic_seven.py    # ì—í”½ì„¸ë¸ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_lost_ark.py      # ë¡œìŠ¤íŠ¸ì•„í¬ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test_utils.py         # ìœ í‹¸ë¦¬í‹° í…ŒìŠ¤íŠ¸
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_mcp_server.py    # MCP ì„œë²„ í†µí•© í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test_all_tools.py     # ì „ì²´ ë„êµ¬ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ performance/
â”‚   â”œâ”€â”€ test_response_time.py # ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test_concurrent.py    # ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸
â””â”€â”€ fixtures/
    â”œâ”€â”€ sample_responses.json # í…ŒìŠ¤íŠ¸ìš© ì‘ë‹µ ë°ì´í„°
    â””â”€â”€ mock_data.py         # ëª¨í‚¹ ë°ì´í„°
```

### í•µì‹¬ ê²€ì¦ í•­ëª©
1. **ê¸°ëŠ¥ ê²€ì¦**: ëª¨ë“  ë„êµ¬ê°€ ì˜¬ë°”ë¥¸ ë°ì´í„° ë°˜í™˜
2. **ì„±ëŠ¥ ê²€ì¦**: ë¦¬ìŠ¤íŠ¸ 10ì´ˆ, ìƒì„¸ 15ì´ˆ ì´ë‚´
3. **ì•ˆì •ì„± ê²€ì¦**: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ì ì ˆí•œ ì²˜ë¦¬
4. **ì¼ê´€ì„± ê²€ì¦**: ëª¨ë“  ê²Œì„ì—ì„œ ë™ì¼í•œ ë°ì´í„° êµ¬ì¡°

## âœ… ì™„ë£Œ ì¡°ê±´
- [ ] ëª¨ë“  ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ 100% ì„±ê³µ
- [ ] ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ë§Œì¡±
- [ ] ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ 90% ì´ìƒ

### ê²€ì¦ ë°©ë²•
```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/ -v --cov=src --cov-report=html

# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
pytest tests/unit/ -v

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/performance/ -v --benchmark-only

# íŠ¹ì • ê²Œì„ í…ŒìŠ¤íŠ¸
pytest tests/unit/test_lordnine.py -v

# í†µí•© í…ŒìŠ¤íŠ¸
pytest tests/integration/ -v
```

### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
```python
# ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ê²€ì¦
@pytest.mark.asyncio
async def test_response_time_requirements():
    # ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ - 10ì´ˆ ì´ë‚´
    start = time.time()
    announcements = await lordnine_scraper.get_announcements()
    duration = time.time() - start
    assert duration < 10.0
    
    # ìƒì„¸ ì¡°íšŒ - 15ì´ˆ ì´ë‚´
    if announcements:
        start = time.time()
        detail = await lordnine_scraper.get_announcement_detail(announcements[0].url)
        duration = time.time() - start
        assert duration < 15.0

# ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
@pytest.mark.asyncio
async def test_concurrent_requests():
    tasks = [
        lordnine_scraper.get_announcements(),
        epic_seven_scraper.get_announcements(),
        lost_ark_scraper.get_announcements()
    ]
    
    start = time.time()
    results = await asyncio.gather(*tasks)
    duration = time.time() - start
    
    assert all(len(result) > 0 for result in results)
    assert duration < 15.0  # ë™ì‹œ ì²˜ë¦¬ ì‹œ 15ì´ˆ ì´ë‚´
```